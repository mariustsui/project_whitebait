{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36983a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arcpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import required libraries\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marcpy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#import re\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arcpy'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import arcpy\n",
    "import tqdm\n",
    "#import re\n",
    "from arcpy import *\n",
    "from arcpy.sa import *\n",
    "from arcpy.ia import *\n",
    "from arcpy.conversion import *\n",
    "#import shutil\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "#import glob\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# Setting up working environment\n",
    "env.overwriteOutput = True\n",
    "env.parallelProcessingFactor = \"90%\"\n",
    "\n",
    "# Setting the study area\n",
    "\n",
    "# A list of string containing the name of the study area\n",
    "locations = ['MOKAU']\n",
    "\n",
    "# A list of the height of Mean High Water Spring in cm according to the sequence of study area defined above\n",
    "tide = [130]\n",
    "\n",
    "##### DIRECTIONS FOR USAGE\n",
    "\n",
    "## 1. PREPARE SOURCE FILE\n",
    "\n",
    "#  i.    Multi-spectral images to be placed in {source_dir}\\RGBI_Tifs\\\n",
    "#  ii.   A folder with the name of the study area in all capital letters without space\n",
    "#  iii.  A Digital Elevation Model named as \"DEM.tif\" placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  iv.   A Digital Surface Model named as \"DSM.tif\" placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  v.    A polygon featuer layer confining the study area with a field names \"NAME\" for the file name of the multispectral images\n",
    "#        named as \"study_area.shp\" to be placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  vi.   A polyline featuer layer indicated the flow of water under the hanging structure (i.e. a bridge),\n",
    "#        named as \"flow_line.shp\" to be placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  vii.  A polyline featuer layer indicated the origin of water coming in,\n",
    "#        named as \"water_origin.shp\" to be placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  viii. A featuer layer containing the groud truth data for land cover classification,\n",
    "#        named as \"training_polygon.shp\" to be placed in {source_dir}\\{name of study area}\\SOURCE\\\n",
    "#  ix.   A featuer layer containing the groud truth data for land cover classification,\n",
    "#        named as \"validation_polygon.shp\" to be placed in {source_dir}\\{name of study area}\\SOURCE\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print current system time\n",
    "def printTime(fn):\n",
    "    print(fn +' at ' +  datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6fe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy source image to destination folder\n",
    "\n",
    "def copyImage(file_list):\n",
    "\n",
    "    img_list = []\n",
    "    \n",
    "    printTime('Copying files started')\n",
    "    for i in tqdm(range(len(file_list))):\n",
    "        source_img = 'D:\\\\AERIAL_IMAGES\\\\RGBI_Tifs\\\\RGBI_'+file_list[i]+'.tif'\n",
    "        img_list.append(source_img)\n",
    "        del(source_img)\n",
    "        gc.collect()\n",
    "    \n",
    "    \n",
    "    MosaicToNewRaster_management(img_list, output_dir, \"RGBI_WHOLE.tif\",'' ,'' ,'' , 4)\n",
    "    \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    rgbi_whole = ExtractByMask(rgbi_whole, tile_index, \"INSIDE\")\n",
    "    rgbi_whole.save( output_dir + \"RGBI_WHOLE.tif\")\n",
    "    \n",
    "    # copy the source DEM & DSM to output folder\n",
    "    s_dem = Raster(source_dir + 'DEM.tif')\n",
    "    s_dem.save( output_dir + 'DEM.tif')\n",
    "    s_dsm = Raster(source_dir + 'DSM.tif')\n",
    "    s_dsm.save( output_dir + 'DSM.tif')\n",
    "    del(img_list, s_dem, s_dsm)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('copyImage done')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dc7069",
   "metadata": {},
   "source": [
    "# Calculate Compound Topographic Index ( CTI / TWI )\n",
    "\n",
    "#####    CTI = ln ( $\\alpha$ / tan $\\beta$ )\n",
    "#####    where\n",
    "#####    $\\alpha$ = ( Flow accumulation area + 1 ) * cellsize\n",
    "#####    $\\beta$ = $Slope^o$ * ( $\\pi$ / 2) / 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b62be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTWI():\n",
    "\n",
    "    SLOPE = Raster( output_dir + 'SLOPE.tif' )\n",
    "    flow_accu = Raster(output_dir + \"FLW_ACCU.tif\")\n",
    "    alpha = ( flow_accu + 1 ) * 1\n",
    "    beta = SLOPE * ( math.pi / 2 ) / 90\n",
    "\n",
    "    TWI = Ln( alpha / Tan(beta) ) \n",
    "    TWI.save( output_dir + 'TWI.tif' )\n",
    "\n",
    "    del(alpha, beta, TWI, SLOPE)\n",
    "    gc.collect()\n",
    "    printTime('getTWI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ba7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare NDVI\n",
    "\n",
    "def getNDVI():\n",
    "        \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    ndvi = NDVI(Raster(rgbi_whole), 4, 1)\n",
    "    ndvi.save( output_dir + \"NDVI.tif\" )\n",
    "    del(ndvi, rgbi_whole)\n",
    "    gc.collect()\n",
    "    printTime('getNDVI done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare NDWI\n",
    "\n",
    "def getNDWI():\n",
    "        \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    bandR = ExtractBand(rgbi_whole, None, \"Band_1\")\n",
    "    bandG = ExtractBand(rgbi_whole, None, \"Band_2\")\n",
    "    bandB = ExtractBand(rgbi_whole, None, \"Band_3\")\n",
    "    bandNIR = ExtractBand(rgbi_whole, None, \"Band_4\")\n",
    "    \n",
    "    NDWI = (bandG - bandNIR) / (bandG + bandNIR)\n",
    "    NDWI.save( output_dir + \"NDWI.tif\")\n",
    "    \n",
    "    del(rgbi_whole, bandR, bandG, bandB, bandNIR, NDWI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('getNDWI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9899f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare EVI - Enhanced Vegetation Index\n",
    "\n",
    "def getEVI():\n",
    "    \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    bandR = ExtractBand(rgbi_whole, None, \"Band_1\")\n",
    "    bandG = ExtractBand(rgbi_whole, None, \"Band_2\")\n",
    "    bandB = ExtractBand(rgbi_whole, None, \"Band_3\")\n",
    "    bandNIR = ExtractBand(rgbi_whole, None, \"Band_4\")\n",
    "    \n",
    "    EVI = (2.5 * (bandNIR - bandR)) / (bandNIR + (2.4 * bandR) + 10000)\n",
    "    EVI.save( output_dir + \"EVI.tif\")\n",
    "    \n",
    "    del(rgbi_whole, bandR, bandG, bandB, bandNIR, EVI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('getEVI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fab8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare GCI - Green Chlorophyll Index\n",
    "\n",
    "def getGCI():\n",
    "    \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    bandR = ExtractBand(rgbi_whole, None, \"Band_1\")\n",
    "    bandG = ExtractBand(rgbi_whole, None, \"Band_2\")\n",
    "    bandB = ExtractBand(rgbi_whole, None, \"Band_3\")\n",
    "    bandNIR = ExtractBand(rgbi_whole, None, \"Band_4\")\n",
    "    \n",
    "    GCI = (bandNIR / bandG) - 1\n",
    "    GCI.save( output_dir + \"GCI.tif\")\n",
    "    \n",
    "    del(rgbi_whole, bandR, bandG, bandB, bandNIR, GCI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('getGCI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef59ed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare GLI - Green Leaf Index\n",
    "\n",
    "def getGLI():\n",
    "    \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    bandR = ExtractBand(rgbi_whole, None, \"Band_1\")\n",
    "    bandG = ExtractBand(rgbi_whole, None, \"Band_2\")\n",
    "    bandB = ExtractBand(rgbi_whole, None, \"Band_3\")\n",
    "    bandNIR = ExtractBand(rgbi_whole, None, \"Band_4\")\n",
    "    \n",
    "    GLI = ((bandG - bandR) + (bandG - bandB)) / ((2 * bandG) + bandR + bandB)\n",
    "    GLI.save( output_dir + \"GLI.tif\")\n",
    "    \n",
    "    del(rgbi_whole, bandR, bandG, bandB, bandNIR, GLI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('getGLI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6878ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare SAVI - Soil Adjusted Vegetation Index\n",
    "\n",
    "def getSAVI():\n",
    "    \n",
    "    rgbi_whole = Raster(output_dir + \"RGBI_WHOLE.tif\")\n",
    "    bandR = ExtractBand(rgbi_whole, None, \"Band_1\")\n",
    "    bandG = ExtractBand(rgbi_whole, None, \"Band_2\")\n",
    "    bandB = ExtractBand(rgbi_whole, None, \"Band_3\")\n",
    "    bandNIR = ExtractBand(rgbi_whole, None, \"Band_4\")\n",
    "    L = 0.5 #Cobertura vegetacion 0-1\n",
    "    \n",
    "    SAVI = ((bandNIR - bandR) / (bandNIR + bandR + L))* (1+L)\n",
    "    SAVI.save( output_dir + \"SAVI.tif\")\n",
    "    \n",
    "    del(rgbi_whole, bandR, bandG, bandB, bandNIR, SAVI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('getSAVI done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a375376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all necessary topographic attributes\n",
    "# i.e. Vegetation height, Slope, Flow direction, Flow accumulation and Basin\n",
    "\n",
    "def getTopoAttr():\n",
    "    DEM = Raster(output_dir+\"DEM.tif\")\n",
    "    DSM = Raster(output_dir+\"DSM.tif\")\n",
    "    \n",
    "    # Create a layer of vegetaion height\n",
    "    VEGE_HEIGHT = Raster(DSM) - Raster(DEM)\n",
    "    VEGE_HEIGHT.save( output_dir + 'VEGE_HEIGHT.tif')\n",
    "    \n",
    "    VH_SHORTGRASS = Con(VEGE_HEIGHT, VEGE_HEIGHT, None, \"Value >=0 AND Value <= 0.05 \") \n",
    "    VH_SHORTGRASS.save( output_dir + 'VH_SHORTGRASS.tif')\n",
    "    VH_LONGGRASS = Con(VEGE_HEIGHT, VEGE_HEIGHT, None, \"Value >0.05 AND Value <= 0.5 \") \n",
    "    VH_LONGGRASS.save( output_dir + 'VH_LONGGRASS.tif')\n",
    "    VH_SHRUB = Con(VEGE_HEIGHT, VEGE_HEIGHT, None, \"Value >0.5 AND Value <= 2 \") \n",
    "    VH_SHRUB.save( output_dir + 'VH_SHRUB.tif')\n",
    "    VH_TREES = Con(VEGE_HEIGHT, VEGE_HEIGHT, None, \"Value >2 \") \n",
    "    VH_TREES.save( output_dir + 'VH_TREES.tif')\n",
    "\n",
    "    # Create a slope for later analysis\n",
    "    SLOPE = Slope(DEM, 'DEGREE')\n",
    "    SLOPE.save( output_dir + 'SLOPE.tif')\n",
    "\n",
    "    # Fill the DEM and create a flow direction\n",
    "    filled_dem = Fill(DEM)\n",
    "    flow_dir = FlowDirection(filled_dem, 'NORMAL', '' , 'D8')\n",
    "    flow_dir.save( output_dir + 'FLW_DIR.tif' )\n",
    "\n",
    "    # Create the flow accumulation from flow direction\n",
    "    flow_accu = FlowAccumulation(flow_dir,'','','D8')\n",
    "    flow_accu.save( output_dir + 'FLW_ACCU.tif' )\n",
    "\n",
    "    # Create a basin from the flow direction\n",
    "    BASIN = Basin(flow_dir)\n",
    "    BASIN.save( output_dir + 'BASIN.tif' )\n",
    "    \n",
    "    del(VEGE_HEIGHT, VH_SHORTGRASS, VH_LONGGRASS, VH_SHRUB, VH_TREES, SLOPE, flow_dir, flow_accu, BASIN, DEM, DSM)\n",
    "    \n",
    "    printTime('getTopoAttr done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation before classification\n",
    "\n",
    "def segmentation():\n",
    "    RGB = Raster( output_dir + 'RGBI_WHOLE.tif')\n",
    "    SEG_RGBI = SegmentMeanShift(RGB, '19.0', '15.0', '15')\n",
    "    SEG_RGBI.save(output_dir + \"SEG_RGBI.tif\")\n",
    "    \n",
    "    del(RGB, SEG_RGBI)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('segmentation done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53014136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all bands into a single raster\n",
    "\n",
    "def compositeBands():\n",
    "    \n",
    "    DEM = Raster(output_dir+\"DEM.tif\")\n",
    "    DSM = Raster(output_dir+\"DSM.tif\")\n",
    "    VEGE_HEIGHT = Raster(output_dir+\"VEGE_HEIGHT.tif\")\n",
    "    SLOPE = Raster(output_dir+\"SLOPE.tif\")\n",
    "    TWI = Raster(output_dir+\"TWI.tif\")\n",
    "    NDVI = Raster(output_dir+\"NDVI.tif\")\n",
    "    NDWI = Raster(output_dir+\"NDWI.tif\")\n",
    "    EVI = Raster(output_dir+\"EVI.tif\")\n",
    "    GCI = Raster(output_dir+\"GCI.tif\")\n",
    "    GLI = Raster(output_dir+\"GLI.tif\")\n",
    "    SAVI = Raster(output_dir+\"SAVI.tif\")\n",
    "    DIS_ACU = Raster(output_dir  + \"\\\\Inundation\\\\DA\\\\DA_\" + str(tidelevel_inCM) + \"CMtide.tif\")\n",
    "    TIDAL_DEP = Raster(output_dir + \"\\\\Inundation\\\\depth_\" + str(tidelevel_inCM) + \"CMtide.tif\")\n",
    "    \n",
    "    #RGBI_WHOLE = Raster(output_dir+\"SEG_RGBI.tif\")\n",
    "    RGBI_WHOLE = Raster( output_dir + 'RGBI_WHOLE.tif')\n",
    "    management.CompositeBands([DEM,DSM,VEGE_HEIGHT,SLOPE,TWI,NDVI,NDWI,EVI,GCI,GLI,SAVI,DIS_ACU,TIDAL_DEP,RGBI_WHOLE], output_dir + \"COMBINED.tif\")\n",
    "    #management.CompositeBands([DEM,DSM,VEGE_HEIGHT,SLOPE,TWI,RGBI_WHOLE], output_dir + \"COMBINED.tif\")\n",
    "    \n",
    "    COMBINED_RASTER = Raster(output_dir + \"COMBINED.tif\")\n",
    "    COMBINED_RASTER.renameBand(1, 'DEM')\n",
    "    COMBINED_RASTER.renameBand(2, 'DSM')\n",
    "    COMBINED_RASTER.renameBand(3, 'VEGE_HEIGHT')\n",
    "    COMBINED_RASTER.renameBand(4, 'SLOPE')\n",
    "    COMBINED_RASTER.renameBand(5, 'TWI')\n",
    "    COMBINED_RASTER.renameBand(6, 'NDVI')\n",
    "    COMBINED_RASTER.renameBand(7, 'NDWI')\n",
    "    COMBINED_RASTER.renameBand(8, 'EVI')\n",
    "    COMBINED_RASTER.renameBand(9, 'GCI')\n",
    "    COMBINED_RASTER.renameBand(10, 'GLI')\n",
    "    COMBINED_RASTER.renameBand(11, 'SAVI')\n",
    "    COMBINED_RASTER.renameBand(12, 'DIS_FMTIDE')\n",
    "    COMBINED_RASTER.renameBand(13, 'TIDAL_DEPT')\n",
    "    COMBINED_RASTER.renameBand(14, 'RED')\n",
    "    COMBINED_RASTER.renameBand(15, 'GREEN')\n",
    "    COMBINED_RASTER.renameBand(16, 'BLUE')\n",
    "    COMBINED_RASTER.renameBand(17, 'NIR')\n",
    "    \n",
    "    del(VEGE_HEIGHT,SLOPE,TWI,NDVI,NDWI,EVI,GCI,GLI,SAVI,DIS_ACU,TIDAL_DEP,RGBI_WHOLE,COMBINED_RASTER, DEM, DSM)\n",
    "    #del(VEGE_HEIGHT,SLOPE,TWI,RGBI_WHOLE,COMBINED_RASTER, DEM, DSM)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('compositeBands done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e8c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training of Random Trees Classifier to create a .ecd definition file\n",
    "\n",
    "\n",
    "def trainRT_classifier():\n",
    "    training_polygon = source_dir + 'training_polygon.shp'\n",
    "    \n",
    "    input_raster = Raster( output_dir + \"COMBINED.tif\")\n",
    "    classifier_definition = output_dir + 'rt_classifier.ecd'\n",
    "    \n",
    "    TrainRandomTreesClassifier(input_raster, training_polygon, classifier_definition, None, 300, 100, 1000)\n",
    "    \n",
    "    del(input_raster)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('trainRT_classifier done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e775d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a supervised classification by Random Trees\n",
    "\n",
    "def classify_combined():\n",
    "    \n",
    "    input_raster = Raster( output_dir + \"COMBINED.tif\")\n",
    "    classifier_definition = output_dir + 'rt_classifier.ecd'\n",
    "        \n",
    "    classified = Classify(input_raster, None, classifier_definition)\n",
    "    classified = ExtractByMask(classified, tile_index, \"INSIDE\")\n",
    "    classified.save( output_dir + \"RT_CLASSIFIED.tif\")\n",
    "    \n",
    "    del(input_raster, classified)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('classify_combined done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596a4aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform accuracy assessment by calculate confusion matrix\n",
    "\n",
    "def accuracy_assessment():\n",
    "    \n",
    "    ## Create accuracy assessment point\n",
    "    validation_polygon = source_dir + 'validation_polygon.shp'\n",
    "    validation_points = output_dir + 'validation_points.shp'\n",
    "    CreateAccuracyAssessmentPoints(validation_polygon, validation_points, \"GROUND_TRUTH\", 1000, \"EQUALIZED_STRATIFIED_RANDOM\")\n",
    "    \n",
    "    ## Update the assessment points\n",
    "    classified_img = output_dir + \"RT_CLASSIFIED.tif\"\n",
    "    assessment_points = output_dir + \"assessment_points.shp\"\n",
    "    \n",
    "    UpdateAccuracyAssessmentPoints(classified_img, validation_points, assessment_points)    \n",
    "    \n",
    "    ## Compute Confusion matrix\n",
    "    matrix = output_dir + 'confusion_matrix.dbf'\n",
    "    #arcpy.DeleteRows_management(matrix)\n",
    "    ComputeConfusionMatrix(assessment_points, matrix)\n",
    "    \n",
    "    del(validation_polygon, validation_points, matrix, assessment_points)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('accuracy_assessment done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac5bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn Flow line into DEM\n",
    "\n",
    "def burnFlowLine():\n",
    "    DEM = Raster(output_dir+\"DEM.tif\")\n",
    "    DSM = Raster(output_dir+\"DSM.tif\")\n",
    "    \n",
    "    # checking if the directory exists, \n",
    "    if not os.path.exists(output_dir + \"\\\\Inundation\\\\hydroAdaptation\\\\\"):\n",
    "        os.makedirs(output_dir + \"\\\\Inundation\\\\hydroAdaptation\\\\\")           # if not, create one\n",
    "    \n",
    "    temp_dem = DEM\n",
    "    temp_dem.save(output_dir + \"\\\\Inundation\\\\hydroAdaptation\\\\temp_dem.tif\")\n",
    "    arcpy.env.extent = temp_dem\n",
    "    flow_line = source_dir + \"flow_line.shp\"\n",
    "    flow_endpoints = output_dir + \"\\\\Inundation\\\\hydroAdaptation\\\\flow_endpoints.shp\"\n",
    "    \n",
    "    endPoint_DEM = output_dir + \"Inundation\\\\hydroAdaptation\\\\endPoint_DEM.shp\"\n",
    "    \n",
    "    endPoint_stats = output_dir + \"Inundation\\\\hydroAdaptation\\\\endPoint_stats.dbf\"\n",
    "    temp_Raster = output_dir + \"\\\\Inundation\\\\hydroAdaptation\\\\temp_Raster.tif\"\n",
    "    \n",
    "    management.FeatureVerticesToPoints(flow_line, flow_endpoints, \"BOTH_ENDS\")\n",
    "    ExtractValuesToPoints(flow_endpoints, temp_dem, endPoint_DEM, \"NONE\", \"VALUE_ONLY\")   \n",
    "    \n",
    "    arcpy.analysis.Statistics(endPoint_DEM, endPoint_stats, [[\"RASTERVALU\", \"MAX\"]], \"ORIG_FID\")\n",
    "    \n",
    "    hydro_joined = management.AddJoin(flow_line, \"FID\", endPoint_stats, \"ORIG_FID\",\"KEEP_ALL\")\n",
    "    \n",
    "    \n",
    "    arcpy.conversion.PolylineToRaster(hydro_joined, \"endPoint_stats.MAX_RASTER\", temp_Raster, \"MAXIMUM_LENGTH\", None, DEM, \"BUILD\")\n",
    "        \n",
    "    temp_Raster2 = Con( IsNull(temp_Raster),9999,temp_Raster)\n",
    "    temp_Raster2.save (output_dir +\"\\\\Inundation\\\\hydroAdaptation\\\\temp_Raster2.tif\")\n",
    "    \n",
    "    adapted_DEM = Con(LessThan(temp_Raster2, 9999), temp_Raster2, temp_dem)\n",
    "    adapted_DEM.save(output_dir + \"adapted_DEM.tif\")\n",
    "    \n",
    "    del(temp_dem,flow_line,flow_endpoints,endPoint_DEM,endPoint_stats,temp_Raster,hydro_joined,temp_Raster2,adapted_DEM, DEM, DSM)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('burnFlowLine done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e187ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inundation model\n",
    "# Inundation model.\n",
    "# Credit to Thomas BalstrÃ¸m, Nov. 9 2021.\n",
    "# Dept. of Geosciences, Univ. of Copenhagen\n",
    "# tb@ign.ku.dk\n",
    "\n",
    "def createInundation():\n",
    "    \n",
    "    DEM = Raster(output_dir+\"DEM.tif\")\n",
    "    DSM = Raster(output_dir+\"DSM.tif\")\n",
    "    \n",
    "    # checking if the directory exists, \n",
    "    if not os.path.exists(output_dir + \"\\\\Inundation\\\\BD\\\\\"):\n",
    "        os.makedirs(output_dir + \"\\\\Inundation\\\\BD\\\\\")           # if not, create one\n",
    "    \n",
    "    # checking if the directory exists, \n",
    "    if not os.path.exists(output_dir + \"\\\\Inundation\\\\DA\\\\\"):\n",
    "        os.makedirs(output_dir + \"\\\\Inundation\\\\DA\\\\\")           # if not, create one\n",
    "        \n",
    "    adapted_DEM = Raster(output_dir + \"adapted_DEM.tif\")\n",
    "    water_origin = source_dir + \"water_origin.shp\"\n",
    "    \n",
    "    in_cost_raster = SetNull(adapted_DEM,1,'Value >=' + str(tidelevel_inCM/100))\n",
    "    BD_CM = output_dir  + \"\\\\Inundation\\\\BD\\\\BD_\" + str(tidelevel_inCM) + \"CMtide.tif\"\n",
    "\n",
    "    this_DA = DistanceAccumulation(water_origin, \"\", \"\", in_cost_raster, \"\", \"BINARY 1 -30 30\", \"\", \"BINARY 1 45\", BD_CM, \"\", \"\", \"\", \"\", \"\", \"\", \"PLANAR\")\n",
    "    this_DA.save(output_dir  + \"\\\\Inundation\\\\DA\\\\DA_\" + str(tidelevel_inCM) + \"CMtide.tif\")\n",
    "\n",
    "    this_inundated = Con(this_DA,tidelevel_inCM)\n",
    "    this_inundated.save(output_dir  + \"\\\\Inundation\\\\inundated_\"+ str(tidelevel_inCM) + \"CMtide.tif\")\n",
    "    management.BuildPyramids(this_inundated)\n",
    "\n",
    "    inundation_depth = (this_inundated/100.0) - DEM\n",
    "    inundation_depth.save(output_dir + \"\\\\Inundation\\\\depth_\" + str(tidelevel_inCM) + \"CMtide.tif\")\n",
    "  \n",
    "    del(in_cost_raster,BD_CM,this_DA,this_inundated,inundation_depth,DEM,DSM)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('createInundation done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab662f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the spawning location for study area\n",
    "\n",
    "def predictLocations():\n",
    "    \n",
    "    DEM = Raster(output_dir+\"DEM.tif\")\n",
    "    DSM = Raster(output_dir+\"DSM.tif\")\n",
    "    VEGE_HEIGHT = Raster(output_dir+\"VEGE_HEIGHT.tif\")\n",
    "    SLOPE = Raster(output_dir+\"SLOPE.tif\")\n",
    "    TWI = Raster(output_dir+\"TWI.tif\")\n",
    "    \n",
    "    ndvi= Raster( output_dir + \"NDVI.tif\" )\n",
    "    NDWI= Raster( output_dir + \"NDWI.tif\" )\n",
    "    EVI= Raster( output_dir + \"EVI.tif\" )\n",
    "    GCI= Raster( output_dir + \"GCI.tif\" )\n",
    "    GLI= Raster( output_dir + \"GLI.tif\" )\n",
    "    SAVI= Raster( output_dir + \"SAVI.tif\" )\n",
    "    \n",
    "    INUNDATED_DEPTH = Raster( output_dir + \"\\\\Inundation\\\\depth_\" + str(tidelevel_inCM) + \"CMtide.tif\" )\n",
    "    INUNDATEDAREA = Raster( output_dir + \"\\\\Inundation\\\\inundated_\"+ str(tidelevel_inCM) + \"CMtide.tif\" )\n",
    "    DIS_ACU = Raster( output_dir+\"\\\\Inundation\\\\DA\\\\DA_\"+ str(tidelevel_inCM) + \"CMtide.tif\" )\n",
    "    VEGETATION = Raster( output_dir + \"RT_CLASSIFIED.tif\" )\n",
    "    SUIT_VEG = Con(VEGETATION, VEGETATION, None, \"Class_name LIKE '%Grass%' OR Class_name LIKE '%Shrub%'\")\n",
    "    POTENTIAL_SITE_INPOINT = output_dir + \"POTENTIAL_SITE_INPOINT.shp\"\n",
    "    \n",
    "\n",
    " \n",
    "    # Use Con() to create the output raster based on the combined conditions\n",
    "    \n",
    "        # - Fairly gentle slope ( less than 5o )\n",
    "        # - With suitable vegetation ( Grassland and shrub )\n",
    "        # - Suitable vegetation height ( 5cm to 5m )\n",
    "        # - Shallow depth of inundation at MHWS ( 3cm to 20cm )\n",
    "\n",
    "    prediction = Con(( (SLOPE<=5) & ( VEGE_HEIGHT >=0.05 ) & ( VEGE_HEIGHT <= 5) & (INUNDATED_DEPTH>=0.03) & (INUNDATED_DEPTH<=0.2) & (SUIT_VEG>=0) ), INUNDATEDAREA)\n",
    "    prediction.save( output_dir + \"PREDICTED_LOCATION.tif\" )\n",
    "    management.BuildPyramids(prediction)\n",
    "    \n",
    "    # Convert the potential spawning location to point feature for regression prediction\n",
    "    arcpy.conversion.RasterToPoint(prediction, POTENTIAL_SITE_INPOINT)\n",
    "    ExtractMultiValuesToPoints(POTENTIAL_SITE_INPOINT, [DEM, DSM, VEGE_HEIGHT, SLOPE, TWI, ndvi, NDWI, EVI, GCI, GLI, SAVI, [INUNDATED_DEPTH, \"TIDAL_DEPT\"], [DIS_ACU, \"DIS_FMTIDE\"]], \"NONE\")\n",
    "\n",
    "    del(DEM, DSM, VEGE_HEIGHT, SLOPE, TWI, INUNDATED_DEPTH, INUNDATEDAREA, VEGETATION, POTENTIAL_SITE_INPOINT)\n",
    "    gc.collect()\n",
    "    \n",
    "    printTime('predictLocations done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b165423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBCR_predict():\n",
    "    \n",
    "    prediction_type = 'PREDICT_FEATURES'\n",
    "    in_features = \"D:\\\\PROJECT_WHITEBAIT\\\\PORT_WAIKATO\\\\OUTPUT\\\\SPAWNING_RECORD.shp\"\n",
    "    variable_predict = 'Spawning'\n",
    "    treat_variable_as_categorical = 'CATEGORICAL'\n",
    "    explanatory_variables = [[\"EVI\", \"false\"], [\"GCI\", \"false\"], [\"GLI\", \"false\"], [\"NDVI\", \"false\"], [\"NDWI\", \"false\"], \n",
    "                             [\"SAVI\", \"false\"], [\"SLOPE\", \"false\"], [\"TWI\", \"false\"], [\"VEGE_HEIGH\", \"false\"], \n",
    "                             [\"TIDAL_DEPT\", \"false\"], [\"DIS_FMTIDE\",\"false\"]]\n",
    "    distance_features = None\n",
    "    explanatory_rasters = None\n",
    "    features_to_predict = output_dir + \"POTENTIAL_SITE_INPOINT.shp\"\n",
    "    output_features = output_dir + \"FBCR_PREDICTED_SITE.shp\"\n",
    "    output_raster = None\n",
    "    explanatory_variable_matching = None\n",
    "    explanatory_distance_matching = None\n",
    "    explanatory_rasters_matching = None\n",
    "    output_trained_features = output_dir + \"FBCR_TRAINEDFEATURE.shp\"\n",
    "    output_importance_table = output_dir + \"FBCR_VARIABLEIMPORTANCE.dbf\"\n",
    "    use_raster_values = False\n",
    "    number_of_trees = 100\n",
    "    minimum_leaf_size = None\n",
    "    maximum_depth = None\n",
    "    sample_size = None\n",
    "    random_variables = None\n",
    "    percentage_for_training = None\n",
    "    output_classification_table = output_dir + \"FBCR_CLASSTABLE.dbf\"\n",
    "    output_validation_table = output_dir + \"FBCR_VALIDATIONTABLE.dbf\"\n",
    "    compensate_sparse_categories = None\n",
    "    number_validation_runs = None\n",
    "    calculate_uncertainty = None\n",
    "    output_trained_model = \"D:\\\\PROJECT_WHITEBAIT\\\\PORT_WAIKATO\\\\OUTPUT\\\\FBCR_TRAINEDMODEL.ssm\"\n",
    "\n",
    "    stats.Forest(prediction_type, in_features, variable_predict, treat_variable_as_categorical, explanatory_variables, distance_features, explanatory_rasters, features_to_predict, output_features, output_raster, explanatory_variable_matching, explanatory_distance_matching, explanatory_rasters_matching, output_trained_features, output_importance_table, use_raster_values, number_of_trees, minimum_leaf_size, maximum_depth, sample_size, random_variables, percentage_for_training, output_classification_table, output_validation_table, compensate_sparse_categories, number_validation_runs, calculate_uncertainty, output_trained_model)\n",
    "    \n",
    "    printTime(\"FBCR_predict Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9882b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Reading all the required file name from an index file\n",
    "    rows = SearchCursor(tile_index)   \n",
    "    file_list = []   # Put all required file name into a list\n",
    "    for row in rows:\n",
    "        file_list.append(row.getValue('NAME'))\n",
    "    \n",
    "    ####################### Performing GIS analysis #################################\n",
    "    \n",
    "    copyImage(file_list)\n",
    "\n",
    "    printTime('Computing topographic attributes started')\n",
    "    getTopoAttr()\n",
    "    printTime('Computing TWI started')\n",
    "    getTWI()\n",
    "    printTime('Computing NDVI started')\n",
    "    getNDVI()\n",
    "    printTime('Computing NDWI started')\n",
    "    getNDWI()\n",
    "    printTime('Computing EVI started')\n",
    "    getEVI()\n",
    "    printTime('Computing GCI started')\n",
    "    getGCI()\n",
    "    printTime('Computing GLI started')\n",
    "    getGLI()\n",
    "    printTime('Computing SAVI started')\n",
    "    getSAVI()    \n",
    "    \n",
    "    ######################## Create inundation model #################################\n",
    "\n",
    "    # Create a flow line adapted DEM\n",
    "    printTime(\"Create flow line adapted DEM started\")\n",
    "    burnFlowLine()\n",
    "\n",
    "    printTime(\"Create inundation model started\")\n",
    "    createInundation()\n",
    "\n",
    "    # Mosaic all attribute into a single raster\n",
    "\n",
    "    #printTime('Segmentation of the aerial image')\n",
    "    #segmentation()\n",
    "\n",
    "    printTime('Composite all bands into one raster started')\n",
    "    compositeBands()\n",
    "\n",
    "    # Perform Classification\n",
    "    printTime('Training of Random Trees Classifier started')\n",
    "    trainRT_classifier()\n",
    "\n",
    "    printTime(\"Classify images started\")\n",
    "    classify_combined()\n",
    "\n",
    "    printTime(\"Calculate confusion matrix started\")\n",
    "    accuracy_assessment()\n",
    "    \n",
    "    ################################# Prediction on potential spawning location #################################\n",
    "    printTime(\"Select potential spawning locations started\")\n",
    "    predictLocations()\n",
    "    \n",
    "    ################################# Prediction spawning location by FBCR #####################################\n",
    "    printTime(\"Prediction spawning location by FBCR started\")\n",
    "    FBCR_predict()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330bf7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for location in locations:\n",
    "    printTime(\"Working on \"+location)\n",
    "    source_dir = 'D:\\\\WHITEBAIT\\\\'\n",
    "    source_dir = source_dir+location+'\\\\SOURCE\\\\'\n",
    "    output_dir = 'D:\\\\WHITEBAIT\\\\'+location\n",
    "\n",
    "    if not os.path.exists(output_dir+'\\\\OUTPUT\\\\'):\n",
    "        os.makedirs(output_dir+'\\\\OUTPUT\\\\')\n",
    "\n",
    "    output_dir = output_dir+'\\\\OUTPUT\\\\'\n",
    "\n",
    "    tile_index = source_dir + 'study_area.shp' # source file containing required DEM and DSM file name and a defined study area\n",
    "    tidelevel_inCM = tide[locations.index(location)]\n",
    "    \n",
    "    main()\n",
    "    printTime(\"Work on \"+location+\" is done\")\n",
    "    print('\\n')\n",
    "\n",
    "printTime(\"Program ended\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436d1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3932bit",
   "language": "python",
   "name": "python3932bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
